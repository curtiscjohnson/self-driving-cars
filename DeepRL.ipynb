{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhaPOG6xt0yn"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rim8iocC1Vva"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "import gc\n",
        "\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "import time\n",
        "from simulation import Simulator, coordinate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulator Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_sim():\n",
        "    # Units are pixels for resolution, degrees for fov, degrees for angle, and pixels for height.\n",
        "    img_size = (128, 72)\n",
        "    cameraSettings = {\n",
        "        # \"resolution\": (1920, 1080),\n",
        "        \"resolution\": img_size,\n",
        "        \"fov\": {\"diagonal\": 77}, # realsense diagonal fov is 77 degrees IIRC\n",
        "        \"angle\": {\"roll\": 0, \"pitch\": 0, \"yaw\": 0}, # don't go too crazy with these, my code should be good up to like... 45 degrees probably? But the math gets unstable\n",
        "        # \"angle\": {\"roll\": 13, \"pitch\": 30, \"yaw\": 30}, # don't go too crazy with these, my code should be good up to like... 45 degrees probably? But the math gets unstable\n",
        "        \"height\": 66 # 8 pixels/inch - represents how high up the camera is relative to the road\n",
        "    }\n",
        "\n",
        "    mapParameters = {\n",
        "        \"loops\": 1,\n",
        "        \"size\": (6, 6),\n",
        "        \"expansions\": 5,\n",
        "        \"complications\": 4\n",
        "    }\n",
        "\n",
        "    # Can also pass car parameters for max/min speed, etc\n",
        "    carParameters = {\n",
        "        \"wheelbase\": 6.5, # inches, influences how quickly the steering will turn the car.  Larger = slower\n",
        "        \"maxSteering\": 30.0, # degrees, extreme (+ and -) values of steering\n",
        "        \"steeringOffset\": 0.0, # degrees, since the car is rarely perfectly aligned\n",
        "        \"minVelocity\": 0.0, # pixels/second, slower than this doesn't move at all.\n",
        "        \"maxVelocity\": 480.0, # pixels/second, 8 pixels/inch, so if the car can move 5 fps that gives us 480 pixels/s top speed\n",
        "    }\n",
        "\n",
        "    sim = Simulator(cameraSettings=cameraSettings)\n",
        "\n",
        "    startLocations = np.array([[0,1], [0,2], [0,3], [0,4], [0,5], [0,6], [0,7], [1,0], [1,1], [1,4], [1,7], [2,2], [2,3], [1,4], [2,5], [2,6], [2,0], [5,1], [3,2], [2,4], [5,5], [5,6], [2,7], [3,0], [7,1], [4,2], [7,3], [5,4], [6,5], [3,7], [4,0], [5,2], [7,4], [7,5], [4,7], [5,0], [7,2], [5,7], [6,0]])\n",
        "    startLoc = random.randint(0, 38)\n",
        "\n",
        "    sim.start(mapSeed='real', mapParameters=mapParameters, carParameters=carParameters, startPoint=(int(startLocations[startLoc, 0]),int(startLocations[startLoc, 1]),0,0))\n",
        "    # sim.start(mapSeed='real', mapParameters=mapParameters, carParameters=carParameters, startPoint=(0,4,0,0))\n",
        "    \n",
        "    where, facing = sim.RealSense.parent.ackermann.pose()\n",
        "    initial_img = sim.RealSense.camera.getImage(where, facing)\n",
        "    return sim, initial_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here, the API for using the simulation is as follows. Steps the entire simulation, returns image, reward from sim.getReward() and a done bool (and we can change what 'done' means. Currently its if reward is negative):\n",
        "\n",
        "```python\n",
        "frame, reward, done = sim.step(steer, speed, display=False) \n",
        "```\n",
        "\n",
        "In order to reset the simulation, you just need to reconstruct the sim object and start it, using the reset_sim() function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV282uYJ2aSw"
      },
      "source": [
        "# DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi_aDdTg2btp"
      },
      "source": [
        "Deep Q-Network (https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) is a Q-learning algorithm that learns values for state-action pairs.\n",
        "\n",
        "Actions are sampled according to an $\\epsilon-greedy$ policy to help with exploration of the state space. Every time an action is sampled, the agent chooses a random action with $\\epsilon$ probability. Otherwise, the agent selects the action with the highest Q-value for a state. $\\epsilon$ decays over time according to $\\epsilon \\gets \\epsilon * epsilon\\_decay$.\n",
        "\n",
        "Tuples of state, action, reward, next_state, and terminal $(s,a,r,s',d)$ are collected during training. Every $learn\\_frequency$ steps $sample\\_size$ tuples are sampled and made into 5 tensors tensors of states, actions, rewarads, next_states, and terminals.\n",
        "\n",
        "The loss for a batch of size N is given below.\n",
        "\n",
        "$Loss=\\frac{1}{N}\\sum \\bigg(Q(s,a) - (r + \\gamma \\underset{a'\\sim A}{max} \\hat{Q}(s',a')(1-d))\\bigg)^2 $\n",
        "\n",
        "Loss is calculated and used to update the Q-Network. The target network $\\hat{Q}$ begins as a copy of the Q network but is not updated by the optimizer. Every $target\\_update$ steps, the target network is updated with the parameters of the Q-Network. This process is a type of bootstrapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q-Value Network\n",
        "class QNetwork(nn.Module):\n",
        "  def __init__(self, action_size, in_channels=3, cnn_outchannels=1, hidden_size=128):\n",
        "    super().__init__()\n",
        "  \n",
        "    self.cnn = nn.Sequential(\n",
        "                            nn.Conv2d(in_channels=in_channels, out_channels=cnn_outchannels*16, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv2d(in_channels=cnn_outchannels*16, out_channels=cnn_outchannels*32, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv2d(in_channels=cnn_outchannels*32, out_channels=cnn_outchannels, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.ReLU()\n",
        "                            )\n",
        "\n",
        "    self.controller = nn.Sequential(\n",
        "                            nn.Linear(128*72, hidden_size),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(hidden_size, action_size)\n",
        "                            )\n",
        "\n",
        "    \n",
        "  def forward(self, img_batch):\n",
        "    \"\"\"Estimate q-values given image\n",
        "    \"\"\"\n",
        "    cnn_output = self.cnn(img_batch.permute([0, 3, 1, 2]))\n",
        "    return self.controller(cnn_output.view(cnn_output.size(0), -1)) # Have to resize the output of the cnn to be accepted  by the linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('frame', 'action', 'next_frame', 'reward'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "class TrainingStats():\n",
        "    def __init__(self, SAVE_FREQUENCY, SAVE_REWARD_THRESHOLD=25):\n",
        "        self.reward_results_dqn = []\n",
        "        self.episode_lengths = []\n",
        "        self.global_steps = 0\n",
        "        self.episodes = 0\n",
        "        self.cum_reward = 0\n",
        "        self.curr_episode_len = 0\n",
        "        self.avg_reward = 0\n",
        "        self.prev_avg_reward = SAVE_REWARD_THRESHOLD\n",
        "        self.SAVE_REWARD_THRESHOLD = SAVE_REWARD_THRESHOLD\n",
        "        self.SAVE_FREQUENCY = SAVE_FREQUENCY\n",
        "\n",
        "    def end_episode(self):\n",
        "        \"\"\"\n",
        "        Returns True if we want to save the network\n",
        "        \"\"\"\n",
        "        flag = False\n",
        "        self.reward_results_dqn.append(self.cum_reward)\n",
        "        self.episode_lengths.append(self.curr_episode_len)\n",
        "\n",
        "        # Save the network if save_frequency steps has passed and it is better than the previous avg_reward\n",
        "        if (self.global_steps % self.SAVE_FREQUENCY == 0) and self.global_steps > self.SAVE_FREQUENCY:\n",
        "            avg_reward = sum(self.reward_results_dqn[:self.SAVE_FREQUENCY]) / self.SAVE_FREQUENCY # get the average reward for the last SAVE_FREQUENCY steps\n",
        "\n",
        "            if (avg_reward > self.prev_avg_reward + self.SAVE_REWARD_THRESHOLD):\n",
        "                self.prev_avg_reward = avg_reward\n",
        "                print(f\"{self.global_steps} steps completed. Average Reward: {avg_reward} > Previous Average: {self.prev_avg_reward}. Saving Model\")\n",
        "                flag = True\n",
        "            \n",
        "        self.episodes += 1\n",
        "        self.cum_reward = 0  # Track cumulative reward per episode\n",
        "        self.curr_episode_len = 0\n",
        "\n",
        "        return flag\n",
        "\n",
        "    def end_frame(self, reward):\n",
        "        self.cum_reward += reward\n",
        "        self.global_steps += 1\n",
        "        self.curr_episode_len += 1\n",
        "\n",
        "    def see_results(self):\n",
        "        # plt.subplot(121)\n",
        "        # plt.plot(self.reward_results_dqn[0::100])\n",
        "        # plt.xlabel(\"Episode Number\")\n",
        "        # plt.ylabel(\"Reward for the Episode\")\n",
        "        # plt.title(\"Training Rewards\")\n",
        "\n",
        "        plt.subplot(111)\n",
        "        plt.plot(self.episode_lengths[0::100])\n",
        "        plt.xlabel(\"Episode Number\")\n",
        "        plt.ylabel(\"Steps in Episode\")\n",
        "        plt.title(\"Episode Lengths\")\n",
        "\n",
        "        print(self.get_printout())\n",
        "\n",
        "\n",
        "    def get_printout(self):\n",
        "        return 'Global Steps: {:5d} Episodes: {:5d} Episode Length: {:4d} Reward: {:3.2f}'.format(self.global_steps, self.episodes, self.curr_episode_len, self.cum_reward)\n",
        "\n",
        "\n",
        "\n",
        "def validate_model(trained_model, action_space, pause_time=0.001, val_episodes=100):\n",
        "    episode_lengths = []\n",
        "\n",
        "    for val_episode in range(1, val_episodes):\n",
        "        # Reset environment\n",
        "        sim, frame = reset_sim()\n",
        "        frame = torch.tensor(frame, dtype=torch.float32).unsqueeze(0).cuda()\n",
        "\n",
        "        done = False\n",
        "        episode_length = 0\n",
        "\n",
        "        # Begin episode\n",
        "        while not done: \n",
        "            with torch.no_grad():\n",
        "                action_idx = trained_model(frame).max(1)[1].view(1, 1)\n",
        "\n",
        "            # Take step\n",
        "            observation, reward, done = sim.step(steer=action_space[action_idx], speed=1.5, display=True)\n",
        "            next_frame = torch.tensor(observation, dtype=torch.float32).unsqueeze(0).cuda()\n",
        "\n",
        "            frame = next_frame  # Set current frame\n",
        "            episode_length += 1\n",
        "            time.sleep(pause_time)\n",
        "            \n",
        "        episode_lengths.append(episode_length)\n",
        "        episode_length = 0\n",
        "\n",
        "    plt.plot(episode_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_mBUvXkT2dHy"
      },
      "outputs": [],
      "source": [
        "def get_action_dqn(network, frame, epsilon, epsilon_decay, action_size, global_steps, REPLAY_SIZE):\n",
        "  \"\"\"Select action according to e-greedy policy and decay epsilon\n",
        "  \"\"\"\n",
        "  if random.uniform(0., 1.) < max(0.1, epsilon) or global_steps < REPLAY_SIZE:\n",
        "    action = random.randint(0,action_size-1) #randint 0-action_space size corresponding to [-30,-20,-10,0,10,20,30] degrees\n",
        "    action = torch.tensor(action).view(1,1)\n",
        "  else:\n",
        "    with torch.no_grad():\n",
        "      action = network(frame).max(1)[1].view(1, 1)\n",
        "  return action.cuda(), epsilon*epsilon_decay\n",
        "\n",
        "  \n",
        "def learn_dqn(memory_buffer, batch_size, optim, q_network, target_network, gamma, episode, target_update):\n",
        "  \"\"\"Update Q-Network according to DQN Loss function\n",
        "     Update Target Network every target_update global steps\n",
        "  \"\"\"\n",
        "  transitions = memory_buffer.sample(batch_size)\n",
        "  batch = Transition(*zip(*transitions))\n",
        "\n",
        "  non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_frame)), dtype=torch.bool).cuda()\n",
        "  non_final_next_states = torch.cat([s for s in batch.next_frame\n",
        "                                          if s is not None])\n",
        "\n",
        "  frame_batch = torch.cat(batch.frame)\n",
        "  action_batch = torch.cat(batch.action).long()\n",
        "  reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "  Q = q_network(frame_batch).gather(1, action_batch)\n",
        "\n",
        "  Q_hat = torch.zeros(batch_size).cuda()\n",
        "  with torch.no_grad():\n",
        "      Q_hat[non_final_mask] = target_network(non_final_next_states).max(1)[0]\n",
        "\n",
        "  b = reward_batch + gamma*Q_hat\n",
        "  Q = torch.squeeze(Q)\n",
        "  \n",
        "  loss = F.mse_loss(Q, b)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  torch.nn.utils.clip_grad_value_(q_network.parameters(), 100)\n",
        "  optim.step()\n",
        "\n",
        "  if episode % target_update == 0:\n",
        "    target_network.load_state_dict(q_network.state_dict())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCafVI552dgg"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sy_r9Wr2eg8",
        "outputId": "ed94a19d-7071-42cd-d62f-03014ea8158a"
      },
      "outputs": [],
      "source": [
        "def dqn_main(ts, episodes, action_space, lr, EPSILON_DECAY, START_TRAINING, MAX_EPISODE_LENGTH, LEARN_FREQUENCY, TARGET_UPDATE, BATCH_SIZE, SAVE_PATH):\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # Init networks\n",
        "  q_network = QNetwork(action_size=len(action_space)).cuda()\n",
        "  target_network = QNetwork(action_size=len(action_space)).cuda()\n",
        "  target_network.load_state_dict(q_network.state_dict()) # copy q_network into target_network\n",
        "\n",
        "  optim = torch.optim.Adam(q_network.parameters(), lr=lr)  # Init optimizer\n",
        "  loop = tqdm(total=episodes, position=0, leave=False)\n",
        "  memory_buffer = ReplayMemory(100000)  # Init episode replay buffer\n",
        "\n",
        "  # HyperParameters that shouldn't change too much\n",
        "  epsilon = 1\n",
        "  CAR_SPEED = 1.5\n",
        "  gamma = 0.99\n",
        "  REPLAY_SIZE = 1000 # Don't let the network pick actions until after this many global steps\n",
        "\n",
        "  for episode in range(1, episodes):\n",
        "    sim, frame = reset_sim()     # Reset environment\n",
        "    frame = torch.tensor(frame, dtype=torch.float32).unsqueeze(0).cuda()\n",
        "    done = False\n",
        "\n",
        "    while not done and ts.curr_episode_len < MAX_EPISODE_LENGTH:\n",
        "      action_idx, epsilon = get_action_dqn(q_network, frame, epsilon, EPSILON_DECAY, len(action_space), ts.global_steps, REPLAY_SIZE) # Select e-greedy action\n",
        "\n",
        "      observation, reward, done = sim.step(steer=action_space[action_idx], speed=CAR_SPEED, display=False)       # Take step in the environment\n",
        "\n",
        "      next_frame = None if done else torch.tensor(observation, dtype=torch.float32).unsqueeze(0).cuda()\n",
        "      reward = torch.tensor([reward]).cuda()\n",
        "\n",
        "      # Store step in replay bufferimg\n",
        "      memory_buffer.push(frame, action_idx, next_frame, reward)\n",
        "      frame = next_frame                        # Set current frame\n",
        "      ts.end_frame(reward.item())\n",
        "\n",
        "      if (ts.global_steps > START_TRAINING) and (ts.global_steps % LEARN_FREQUENCY == 0):\n",
        "        learn_dqn(memory_buffer, BATCH_SIZE, optim, q_network, target_network, gamma, episode, TARGET_UPDATE)     # Train\n",
        "\n",
        "    loop.update(1)\n",
        "    loop.set_description(ts.get_printout())\n",
        "\n",
        "    if ts.end_episode():\n",
        "      torch.save(q_network, f'{SAVE_PATH}{episode}.pt')\n",
        "  \n",
        "  return q_network, ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(model, SAVE_PATH):\n",
        "    torch.save(model, f'{SAVE_PATH}.pt')\n",
        "\n",
        "def load_model(action_size, PATH):\n",
        "    model = QNetwork(action_size)\n",
        "    model = torch.load(PATH)\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global Steps:  4141 Episodes:    99 Episode Length:    0 Reward: 0.00\n",
            "Total Training Time: 39.061163663864136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Hyper parameters\n",
        "########################################################################\n",
        "ts = TrainingStats(SAVE_FREQUENCY=1000)\n",
        "episodes = 100\n",
        "# action_space = [-30,-20,-10,0,10,20,30]\n",
        "action_space = [-30,-15,0,15,30]                        # CHANGED FROM LEN 2->5\n",
        "lr = 0.00025\n",
        "EPSILON_DECAY = .9999\n",
        "\n",
        "START_TRAINING = 200\n",
        "MAX_EPISODE_LENGTH = 10000\n",
        "LEARN_FREQUENCY = 3\n",
        "TARGET_UPDATE = 2000\n",
        "BATCH_SIZE = 32\n",
        "SAVE_PATH = './rl_models/trying_7actions_'\n",
        "#############################################################################\n",
        "start = time.time()\n",
        "trained_model, ts = dqn_main(ts, episodes, action_space, lr, EPSILON_DECAY, START_TRAINING, MAX_EPISODE_LENGTH, LEARN_FREQUENCY, TARGET_UPDATE, BATCH_SIZE, SAVE_PATH)\n",
        "end = time.time()\n",
        "save_model(trained_model, f'{SAVE_PATH}final_model')\n",
        "ts.see_results()\n",
        "print(f\"Total Training Time: {(end-start)/60} min\")\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./rl_models/working_2actmodel.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[15], line 98\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(trained_model, action_space, val_episodes)\u001b[0m\n\u001b[1;32m     95\u001b[0m     action_idx \u001b[38;5;241m=\u001b[39m trained_model(frame)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Take step\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m observation, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m next_frame \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(observation, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    101\u001b[0m frame \u001b[38;5;241m=\u001b[39m next_frame  \u001b[38;5;66;03m# Set current frame\u001b[39;00m\n",
            "File \u001b[0;32m/auto/fsg/dcheney1/self-driving-cars/simulation/Simulator.py:128\u001b[0m, in \u001b[0;36mSimulator.step\u001b[0;34m(self, steer, speed, display)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mmap\u001b[39m \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mline(\u001b[39mmap\u001b[39m, carPlace\u001b[39m.\u001b[39masInt(), (carPlace \u001b[39m+\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m coordinate\u001b[39m.\u001b[39munitFromAngle(\n\u001b[1;32m    124\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mackermann\u001b[39m.\u001b[39mcurrentState\u001b[39m.\u001b[39mtheta \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mackermann\u001b[39m.\u001b[39mcurrentState\u001b[39m.\u001b[39mdelta \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mackermann\u001b[39m.\u001b[39mcurrentState\u001b[39m.\u001b[39msteeringOffset,\n\u001b[1;32m    125\u001b[0m         isRadians\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\u001b[39m.\u001b[39masInt(), (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m), \u001b[39m3\u001b[39m)\n\u001b[1;32m    127\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mmap\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m     cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m frame,reward,done\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = load_model(2, './rl_models/working_2actmodel.pt')\n",
        "validate_model(model, [-30, 30], 10, pause_time=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Next Steps:\n",
        "    - Get it to train on a more complicated (random?) map\n",
        "    - Dial in rewards?\n",
        "    \n",
        "\"\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
